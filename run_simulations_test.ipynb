{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from agents import BetaAgent\n",
    "from model import Model\n",
    "from network_utils import *\n",
    "from network_randomization import *\n",
    "from network_generation import *\n",
    "from simulation_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.30it/s]\n"
     ]
    }
   ],
   "source": [
    "n_simulations = 10\n",
    "G_default = barabasi_albert_directed(200,5)\n",
    "\n",
    "num_cores = cpu_count()  # Get the number of available CPU cores\n",
    "print(num_cores)\n",
    "\n",
    "# Define a partial function to pass G_perceptron to generate_parameters_empir\n",
    "# This ensures that generate_parameters_empir is called with the correct argument within the pool\n",
    "# The 'partial' function allows you to create a new function with some of the arguments pre-filled.\n",
    "from functools import partial\n",
    "generate_params_with_G = partial(generate_parameters, G=G_default)\n",
    "\n",
    "with Pool(num_cores) as pool:\n",
    "    # Use tqdm to display a progress bar\n",
    "    # Now, 'generate_params_with_G' is the function that will be executed by each worker.\n",
    "    # Each worker will receive an index from 'range(n_simulations)' as its argument,\n",
    "    # which is ignored in 'generate_params_with_G' but is required by the 'imap_unordered' function.\n",
    "    param_dict = list(tqdm.tqdm(pool.imap_unordered(generate_params_with_G, range(n_simulations)), total=n_simulations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'randomized': True,\n",
       " 'unique_id': '31104bc0f41f4c60a37bbfcdc6d0ecec',\n",
       " 'n_agents': 200,\n",
       " 'network': <networkx.classes.digraph.DiGraph at 0x128614450>,\n",
       " 'uncertainty': 0.0008606075186619158,\n",
       " 'n_experiments': 10,\n",
       " 'p_rewiring': 0.19303359869623138,\n",
       " 'average_degree': 4.925,\n",
       " 'degree_gini_coefficient': np.float64(0.7300050761421321),\n",
       " 'approx_average_clustering_coefficient': 0.1266160601059239,\n",
       " 'diameter': 201,\n",
       " 'avg_path_length': 201,\n",
       " 'degree_entropy': np.float64(2.23335966406045)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(param_dict))\n",
    "param_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running simulations:   2%|▏         | 2/100 [05:03<4:08:01, 151.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/GitRepositories/e_network_inequality/.conda/lib/python3.11/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run simulations in parallel\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_cores) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m----> 3\u001b[0m     simulation_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_simulation_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRunning simulations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Convert results to a DataFrame\u001b[39;00m\n\u001b[1;32m      7\u001b[0m basic_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simulation_results)\n",
      "File \u001b[0;32m~/GitRepositories/e_network_inequality/.conda/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/GitRepositories/e_network_inequality/.conda/lib/python3.11/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m~/GitRepositories/e_network_inequality/.conda/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run simulations in parallel\n",
    "with Pool(num_cores) as pool:\n",
    "    simulation_results = list(tqdm.tqdm(pool.imap_unordered(run_simulation_wrapper, param_dict),\n",
    "                                        total=len(param_dict), desc=\"Running simulations\"))\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "basic_results_df = pd.DataFrame(simulation_results)\n",
    "display(basic_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_results_df.to_csv(\"basic_results_df.csv\", index=False)  # Saves without index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Plotting Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df, target_variable=\"share_of_correct_agents_at_convergence\"):\n",
    "     # Select numerical columns excluding unique ID and target variable\n",
    "    numerical_columns = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    numerical_columns.remove(target_variable)  # Remove target variable from independent variables\n",
    "\n",
    "    # Generate scatter plots for each numerical column against the target variable\n",
    "    num_plots = len(numerical_columns)\n",
    "    fig, axes = plt.subplots(nrows=(num_plots + 1) // 2, ncols=2, figsize=(10, num_plots * 2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, column in enumerate(numerical_columns):\n",
    "        axes[i].scatter(df[column], df[target_variable], alpha=0.5)\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel(target_variable)\n",
    "        axes[i].set_title(f\"{column} vs {target_variable}\")\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(basic_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(basic_results_df, target_variable=\"convergence_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'randomized': True,\n",
       " 'unique_id': '8eb13478fde749adb4cfae64345518c1',\n",
       " 'n_agents': 138,\n",
       " 'network': <networkx.classes.digraph.DiGraph at 0x128f25350>,\n",
       " 'uncertainty': 0.0012134387156154294,\n",
       " 'n_experiments': 4,\n",
       " 'p_rewiring': 0.15087648377076274,\n",
       " 'average_degree': 2.152173913043478,\n",
       " 'degree_gini_coefficient': np.float64(0.7128043722246622),\n",
       " 'approx_average_clustering_coefficient': 0.07977447698960605,\n",
       " 'diameter': 139,\n",
       " 'avg_path_length': 139,\n",
       " 'degree_entropy': np.float64(1.7283771414415292)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./empirical_networks/perc_pruned_lcc.pkl', 'rb') as f:\n",
    "  G_perceptron = pickle.load(f)\n",
    "\n",
    "n_agents = G_perceptron.number_of_nodes()\n",
    "print(n_agents)\n",
    "\n",
    "# Create a mapping from node names to indexes\n",
    "mapping = {node: index for index, node in enumerate(G_perceptron.nodes())}\n",
    "\n",
    "# Relabel the nodes in the graph\n",
    "G_perceptron_indexed = nx.relabel_nodes(G_perceptron, mapping)\n",
    "G_default = G_perceptron_indexed\n",
    "\n",
    "\n",
    "n_simulations = 10\n",
    "\n",
    "num_cores = cpu_count()  # Get the number of available CPU cores\n",
    "print(num_cores)\n",
    "\n",
    "# Define a partial function to pass G_perceptron to generate_parameters_empir\n",
    "# This ensures that generate_parameters_empir is called with the correct argument within the pool\n",
    "# The 'partial' function allows you to create a new function with some of the arguments pre-filled.\n",
    "from functools import partial\n",
    "generate_params_with_G = partial(generate_parameters, G=G_default)\n",
    "\n",
    "with Pool(num_cores) as pool:\n",
    "    # Use tqdm to display a progress bar\n",
    "    # Now, 'generate_params_with_G' is the function that will be executed by each worker.\n",
    "    # Each worker will receive an index from 'range(n_simulations)' as its argument,\n",
    "    # which is ignored in 'generate_params_with_G' but is required by the 'imap_unordered' function.\n",
    "    param_dict = list(tqdm.tqdm(pool.imap_unordered(generate_params_with_G, range(n_simulations)), total=n_simulations))\n",
    "    \n",
    "param_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running simulations:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Run simulations in parallel\n",
    "with Pool(num_cores) as pool:\n",
    "    simulation_results = list(tqdm.tqdm(pool.imap_unordered(run_simulation_wrapper, param_dict),\n",
    "                                        total=len(param_dict), desc=\"Running simulations\"))\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "basic_results_df = pd.DataFrame(simulation_results)\n",
    "display(basic_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
