{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7792a261",
   "metadata": {},
   "source": [
    "# Colinearity and Other Statistical Methods\n",
    "\n",
    "In this notebook I first measure colinearity and show that the situation is pretty bad. Then, I consider some other statistical methods:\n",
    "1. Multiple linear regressions: we fix the bandit features (_uncertainty_ and _n-experiments_) and do multiple linear regressions, one for each combination of network features. \n",
    "2. Ridge and Lasso regressions: these methods use regularization techniques. Especially Lasso might be interesting because it can be viewed as a feature selection method. Overall, Lasso gives the desired results: for densify, Lasso only selects _Average Degree_ and not the other network features; for equalize, Lasso only selects _Gini_ and not _Clustering_. \n",
    "3. Bootstrapped Elastic Net regressions: this method can be used for robust feature selection. It uses 5-fold cross-validation to select optimal alpha and l1_ratio. To my surprise, this statistical method always selected all network features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9990414c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "282120e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import ElasticNetCV, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37f69d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'n_agents': 'Number of Agents',\n",
    "    'p_rewiring': 'Probability of Rewiring',\n",
    "    'uncertainty': 'Problem Easiness',\n",
    "    'n_experiments': 'Number of Experiments',\n",
    "    'share_of_correct_agents_at_convergence': 'Share of correct agents', # is this CORRECT ?!!?!?!?\n",
    "    #'share_of_correct_agents_at_convergence':'Share of correct agents',\n",
    "    'mean_degree': 'Mean Degree',\n",
    "    'ba_degree':'BA-Degree',\n",
    "    'convergence_step': 'Steps until convergence (log)',\n",
    "    'approx_average_clustering_coefficient':'Clustering Coeff.',\n",
    "    'average_degree': 'Average Degree',\n",
    "    'degree_gini_coefficient': 'Degree Gini Coeff.',\n",
    "    'avg_path_length': 'Avg. Path Length',\n",
    "    'degree_entropy': 'Degree Entropy',\n",
    "    'diameter': 'Diameter',\n",
    "    'reachability_dominator_set_size': 'Reach. Dominator SS',\n",
    "    'reachability_dominator_set_ratio': 'Reach. Dominator SR',\n",
    "    'condensation_graph_size': 'Cond. Graph Size',\n",
    "    'condensation_graph_ratio': 'Cond. Graph Ratio',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d554a9",
   "metadata": {},
   "source": [
    "## Measuring colinearity: it's not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1f19763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VIF_interpretation(score: float) -> str:\n",
    "    if score >= 5:\n",
    "        return \"high multicollinearity\"\n",
    "    elif score > 1.5:\n",
    "        return \"acceptable multicollinearity\"\n",
    "    elif score > 1:\n",
    "        return \"minimal multicollinearity\"\n",
    "    elif score == 1:\n",
    "        return \"no multicollinearity\"\n",
    "    else:\n",
    "        return \"something went wrong\"\n",
    "\n",
    "\n",
    "def compute_vif(\n",
    "    df: pd.DataFrame,\n",
    "    columns_corr: list[str] = [\"degree_average\", \"degree_gini\", \"clustering_average\"],\n",
    "):\n",
    "    X = df[columns_corr].copy()\n",
    "    X_const = X\n",
    "    X_const = sm.add_constant(X)\n",
    "\n",
    "    vif_data = pd.DataFrame(\n",
    "        {\n",
    "            \"variable\": X_const.columns,\n",
    "            \"VIF\": [\n",
    "                variance_inflation_factor(X_const.values, i)\n",
    "                for i in range(X_const.shape[1])\n",
    "            ],\n",
    "            \"VIF interpretation\": [\n",
    "                VIF_interpretation(variance_inflation_factor(X_const.values, i))\n",
    "                for i in range(X_const.shape[1])\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    vif_df = pd.DataFrame(vif_data, columns=[\"variable\", \"VIF\", \"VIF interpretation\"])\n",
    "    vif_df = vif_df[vif_df[\"variable\"].isin(columns_corr)]\n",
    "    return vif_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2acdc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_interpretation(\n",
    "      score: float\n",
    ") -> str:\n",
    "    score_abs = abs(score)\n",
    "    if score_abs == 0:\n",
    "        return \"no \"\n",
    "    elif score_abs <= 0.3:\n",
    "        return \"weak\"\n",
    "    elif score_abs <= 0.5:\n",
    "        return \"medium\"\n",
    "    elif score_abs <= 1:\n",
    "        return \"strong\"\n",
    "    else:\n",
    "        return \"error\"\n",
    "\n",
    "def compute_correlations(\n",
    "    df: pd.DataFrame, \n",
    "    columns_corr: list[str] = [\"degree_average\", \"degree_gini\",'clustering_average'],\n",
    ") -> None:\n",
    "    df_corr = df[columns_corr].corr(method='pearson')\n",
    "    display(df_corr)\n",
    "    df_corr_interpretation = df_corr.map(pearson_interpretation)\n",
    "    display(df_corr_interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f319b71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree_average</th>\n",
       "      <th>degree_gini</th>\n",
       "      <th>clustering_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>degree_average</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.147334</td>\n",
       "      <td>-0.066165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_gini</th>\n",
       "      <td>-0.147334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clustering_average</th>\n",
       "      <td>-0.066165</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    degree_average  degree_gini  clustering_average\n",
       "degree_average            1.000000    -0.147334           -0.066165\n",
       "degree_gini              -0.147334     1.000000            0.015240\n",
       "clustering_average       -0.066165     0.015240            1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree_average</th>\n",
       "      <th>degree_gini</th>\n",
       "      <th>clustering_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>degree_average</th>\n",
       "      <td>strong</td>\n",
       "      <td>weak</td>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_gini</th>\n",
       "      <td>weak</td>\n",
       "      <td>strong</td>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clustering_average</th>\n",
       "      <td>weak</td>\n",
       "      <td>weak</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   degree_average degree_gini clustering_average\n",
       "degree_average             strong        weak               weak\n",
       "degree_gini                  weak      strong               weak\n",
       "clustering_average           weak        weak             strong"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>VIF</th>\n",
       "      <th>VIF interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>degree_average</td>\n",
       "      <td>1.026477</td>\n",
       "      <td>minimal multicollinearity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>degree_gini</td>\n",
       "      <td>1.022221</td>\n",
       "      <td>minimal multicollinearity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clustering_average</td>\n",
       "      <td>1.004428</td>\n",
       "      <td>minimal multicollinearity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable       VIF         VIF interpretation\n",
       "1      degree_average  1.026477  minimal multicollinearity\n",
       "2         degree_gini  1.022221  minimal multicollinearity\n",
       "3  clustering_average  1.004428  minimal multicollinearity"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_densify = pd.read_csv(\"data/simulation_densify.csv\")\n",
    "network_features = [\"degree_average\", \"degree_gini\",\"clustering_average\"]\n",
    "compute_correlations(df_densify, columns_corr=network_features)\n",
    "compute_vif(df_densify, columns_corr=network_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85c8b0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree_gini</th>\n",
       "      <th>clustering_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>degree_gini</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clustering_average</th>\n",
       "      <td>0.168868</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    degree_gini  clustering_average\n",
       "degree_gini            1.000000            0.168868\n",
       "clustering_average     0.168868            1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree_gini</th>\n",
       "      <th>clustering_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>degree_gini</th>\n",
       "      <td>strong</td>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clustering_average</th>\n",
       "      <td>weak</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   degree_gini clustering_average\n",
       "degree_gini             strong               weak\n",
       "clustering_average        weak             strong"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>VIF</th>\n",
       "      <th>VIF interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>degree_gini</td>\n",
       "      <td>1.029354</td>\n",
       "      <td>minimal multicollinearity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clustering_average</td>\n",
       "      <td>1.029354</td>\n",
       "      <td>minimal multicollinearity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable       VIF         VIF interpretation\n",
       "1         degree_gini  1.029354  minimal multicollinearity\n",
       "2  clustering_average  1.029354  minimal multicollinearity"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_equalize = pd.read_csv(\"data/simulation_equalize.csv\")\n",
    "network_features = [\"degree_gini\", \"clustering_average\"]\n",
    "compute_correlations(df_equalize, columns_corr=network_features)\n",
    "compute_vif(df_equalize, columns_corr=network_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891a9ae",
   "metadata": {},
   "source": [
    "## New multiple linear regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1623718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_densify = pd.read_csv(\"data/simulation_densify.csv\")\n",
    "df_equalize = pd.read_csv(\"data/simulation_equalize.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d945aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_subsets(\n",
    "        df: pd.DataFrame, \n",
    "        fixed_predictors = ['uncertainty', 'n_experiments'], \n",
    "        main_predictors = ['degree_average', 'degree_gini', 'clustering_average'], \n",
    "        target = 'conclusion'\n",
    "    ):\n",
    "\n",
    "    # Generate all non-empty subsets of the first three predictors\n",
    "    def all_subsets(lst):\n",
    "        return chain.from_iterable(combinations(lst, r) for r in range(0, len(lst)+1))\n",
    "\n",
    "    df_renamed = df.rename(columns={\"degree_gini_coefficient\": \"gini\", \"approx_average_clustering_coefficient\": \"clustering\"})\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for subset in all_subsets(main_predictors):\n",
    "        predictors = list(subset) + fixed_predictors\n",
    "        X = df_renamed[predictors]\n",
    "        y = df_renamed[target]\n",
    "\n",
    "        # Normalize predictors and keep column names by converting back to a DataFrame\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=predictors, index=X.index)\n",
    "        \n",
    "        # Add intercept (preserves column names so statsmodels will show informative coef names)\n",
    "        X_scaled_df = sm.add_constant(X_scaled_df, has_constant='add')\n",
    "        \n",
    "        # Fit OLS model\n",
    "        model = sm.OLS(y, X_scaled_df).fit()\n",
    "        \n",
    "        # Build a tidy results table for this model\n",
    "        params = model.params\n",
    "        pvals = model.pvalues.reindex(params.index)\n",
    "        results_df = pd.DataFrame({\n",
    "            'Predictor': params.index,\n",
    "            'Coefficient': params.values,\n",
    "            'P-value': pvals.values\n",
    "        })\n",
    "\n",
    "        # Print formatted output: predictor table and R-squared\n",
    "        print(f\"Predictors: {predictors}\")\n",
    "        print(f\"R-squared: {model.rsquared:.4f}\")\n",
    "        print(f\"R-squared-adj: {model.rsquared_adj:.4f}\\n\")\n",
    "        print(results_df.to_string(index=False, float_format='{:.6f}'.format))\n",
    "\n",
    "        print('\\n'+'-'*90+'\\n')\n",
    "\n",
    "        # Optionally store results for later\n",
    "        # results.append({'predictors': predictors, 'results_df': results_df, 'r2': model.rsquared})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92b68e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['uncertainty', 'n_experiments']\n",
      "R-squared: 0.4976\n",
      "R-squared-adj: 0.4974\n",
      "\n",
      "    Predictor  Coefficient  P-value\n",
      "        const     0.762036 0.000000\n",
      "  uncertainty     0.051198 0.000000\n",
      "n_experiments     0.026178 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.5435\n",
      "R-squared-adj: 0.5432\n",
      "\n",
      "    Predictor  Coefficient  P-value\n",
      "        const     0.762036 0.000000\n",
      "  degree_gini    -0.017435 0.000000\n",
      "  uncertainty     0.051191 0.000000\n",
      "n_experiments     0.026517 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.5010\n",
      "R-squared-adj: 0.5007\n",
      "\n",
      "         Predictor  Coefficient  P-value\n",
      "             const     0.762036 0.000000\n",
      "clustering_average    -0.004762 0.000000\n",
      "       uncertainty     0.051210 0.000000\n",
      "     n_experiments     0.026218 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.5440\n",
      "R-squared-adj: 0.5436\n",
      "\n",
      "         Predictor  Coefficient  P-value\n",
      "             const     0.762036 0.000000\n",
      "       degree_gini    -0.017119 0.000000\n",
      "clustering_average    -0.001874 0.017577\n",
      "       uncertainty     0.051195 0.000000\n",
      "     n_experiments     0.026526 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_subsets(df_equalize, main_predictors=['degree_gini', 'clustering_average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33afc4d",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- `equalize` keeps average degree fixed, but tries to maximally change Gini while keeping Clustering somewhat equal.\n",
    "- Adding Gini to the bandit predictors increases the $R^2$ by about 5%.\n",
    "- Adding Clustering to the bandit predictors increases the $R^2$ by about 1%.\n",
    "- The coefficients of Gini and Clustering do not change much across multiple conditions. \n",
    "- The $R^2$ when including Gini is basically the same as the $R^2$ when including both Gini and Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "63565541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['uncertainty', 'n_experiments']\n",
      "R-squared: 0.4381\n",
      "R-squared-adj: 0.4379\n",
      "\n",
      "    Predictor  Coefficient  P-value\n",
      "        const     0.758856 0.000000\n",
      "  uncertainty     0.044228 0.000000\n",
      "n_experiments     0.022850 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['degree_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4842\n",
      "R-squared-adj: 0.4839\n",
      "\n",
      "     Predictor  Coefficient  P-value\n",
      "         const     0.758856 0.000000\n",
      "degree_average     0.016064 0.000000\n",
      "   uncertainty     0.044793 0.000000\n",
      " n_experiments     0.023054 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4399\n",
      "R-squared-adj: 0.4396\n",
      "\n",
      "    Predictor  Coefficient  P-value\n",
      "        const     0.758856 0.000000\n",
      "  degree_gini    -0.003164 0.000065\n",
      "  uncertainty     0.044214 0.000000\n",
      "n_experiments     0.022891 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4381\n",
      "R-squared-adj: 0.4378\n",
      "\n",
      "         Predictor  Coefficient  P-value\n",
      "             const     0.758856 0.000000\n",
      "clustering_average     0.000088 0.911179\n",
      "       uncertainty     0.044228 0.000000\n",
      "     n_experiments     0.022852 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['degree_average', 'degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4844\n",
      "R-squared-adj: 0.4839\n",
      "\n",
      "     Predictor  Coefficient  P-value\n",
      "         const     0.758856 0.000000\n",
      "degree_average     0.015944 0.000000\n",
      "   degree_gini    -0.000815 0.288921\n",
      "   uncertainty     0.044785 0.000000\n",
      " n_experiments     0.023063 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['degree_average', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4845\n",
      "R-squared-adj: 0.4841\n",
      "\n",
      "         Predictor  Coefficient  P-value\n",
      "             const     0.758856 0.000000\n",
      "    degree_average     0.016141 0.000000\n",
      "clustering_average     0.001162 0.127008\n",
      "       uncertainty     0.044794 0.000000\n",
      "     n_experiments     0.023087 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4399\n",
      "R-squared-adj: 0.4395\n",
      "\n",
      "         Predictor  Coefficient  P-value\n",
      "             const     0.758856 0.000000\n",
      "       degree_gini    -0.003166 0.000065\n",
      "clustering_average     0.000138 0.861753\n",
      "       uncertainty     0.044214 0.000000\n",
      "     n_experiments     0.022895 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Predictors: ['degree_average', 'degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4846\n",
      "R-squared-adj: 0.4841\n",
      "\n",
      "         Predictor  Coefficient  P-value\n",
      "             const     0.758856 0.000000\n",
      "    degree_average     0.016021 0.000000\n",
      "       degree_gini    -0.000822 0.284787\n",
      "clustering_average     0.001167 0.125451\n",
      "       uncertainty     0.044786 0.000000\n",
      "     n_experiments     0.023097 0.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_subsets(df_densify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ebe4bb",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- `densify` increases average degree, while trying to keep Gini and Clustering somewhat equal.\n",
    "- Adding average-degree to the bandit predictors only increases the $R^2$ by roughly 4%.\n",
    "- The coefficients of average-degree, Gini and Clustering do not change much across multiple conditions. \n",
    "- The $R^2$ when including average-degree is basically the same as the $R^2$ when including Gini and Clustering too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd627644",
   "metadata": {},
   "source": [
    "## Ridge & Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f60e9c",
   "metadata": {},
   "source": [
    "Lasso and Ridge regression are both regularization techniques used to prevent overfitting in linear regression models by adding a penalty term to the loss function.\n",
    " The key difference lies in the type of penalty applied: Ridge regression uses L2 regularization, which adds a penalty proportional to the sum of the squared coefficients, while Lasso regression uses L1 regularization, which adds a penalty proportional to the sum of the absolute values of the coefficients.\n",
    "\n",
    "This fundamental difference leads to distinct behaviors. Ridge regression shrinks the coefficients of less important features toward zero but does not set them exactly to zero, meaning all predictors remain in the model.\n",
    " This approach is beneficial when all features are potentially relevant and the goal is to reduce overfitting without eliminating variables.\n",
    " In contrast, Lasso regression can set some coefficients exactly to zero, effectively performing automatic feature selection by excluding irrelevant or redundant predictors from the model.\n",
    " This results in a simpler, more interpretable model with fewer features.\n",
    "\n",
    "The geometric interpretation explains this behavior: the L1 constraint in Lasso creates a diamond-shaped boundary with corners, making it more likely for the solution to land on a corner where a coefficient is zero. The L2 constraint in Ridge forms a circular boundary, which is rotationally invariant and less likely to produce zero coefficients.\n",
    " Consequently, Lasso is preferred when feature selection is important or when a sparse solution is desired, such as in high-dimensional data where only a few features are expected to be relevant. Ridge is more suitable when all features are believed to contribute to the outcome, such as in predicting house prices where multiple factors like size, location, and number of bedrooms are all potentially important.\n",
    "\n",
    "Lasso can be more sensitive to outliers due to the absolute value in its penalty term, while Ridge is generally more robust.\n",
    " Computationally, Ridge regression is typically faster as it does not involve feature selection, whereas Lasso may be slower due to the need to identify which coefficients to set to zero.\n",
    " Both methods require tuning a hyperparameter (lambda) to control the strength of regularization.\n",
    " In cases where features are correlated, Elastic Net, which combines both L1 and L2 penalties, can be advantageous by balancing feature selection and handling of correlated predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86b2c9",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "- For densify: LASSO selects Average Degree as the most relevant network feature. It consistently drives Gini and Clustering to zero, as expected. \n",
    "- For equalize: LASSO selects Gini as the most relevant network feature. It consistently drives Clustering to zero, as expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513603f4",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7154dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_subsets(\n",
    "    df: pd.DataFrame, \n",
    "    fixed_predictors = ['uncertainty', 'n_experiments'], \n",
    "    main_predictors = ['degree_average', 'degree_gini', 'clustering_average'], \n",
    "    target = 'conclusion',\n",
    "    alpha=1.0 # Regularization strength\n",
    "):\n",
    "    \"\"\"\n",
    "    Fits Ridge regression models for all subsets of main_predictors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate all non-empty subsets\n",
    "    def all_subsets(lst):\n",
    "        # Includes the empty subset for completeness, which results in fixed_predictors only\n",
    "        return chain.from_iterable(combinations(lst, r) for r in range(0, len(lst)+1))\n",
    "    \n",
    "    for subset in all_subsets(main_predictors):\n",
    "        predictors = list(subset) + fixed_predictors\n",
    "        X = df[predictors]\n",
    "        y = df[target]\n",
    "\n",
    "        # Normalize predictors\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=predictors, index=X.index)\n",
    "        \n",
    "        # Fit Ridge model\n",
    "        # NOTE: Ridge and Lasso automatically include an intercept (constant) by default.\n",
    "        model = Ridge(alpha=alpha, random_state=42) # random_state for reproducibility\n",
    "        model.fit(X_scaled_df, y)\n",
    "        \n",
    "        # Extract results\n",
    "        # Intercept is stored separately in sklearn\n",
    "        coef_names = ['Intercept'] + predictors\n",
    "        coefficients = [model.intercept_] + list(model.coef_)\n",
    "        r_squared = model.score(X_scaled_df, y) # R^2 on the training data\n",
    "        \n",
    "        # Build a tidy results table for this model\n",
    "        results_df = pd.DataFrame({\n",
    "            'Predictor': coef_names,\n",
    "            'Coefficient': coefficients,\n",
    "        })\n",
    "\n",
    "        # Print formatted output: predictor table and R-squared\n",
    "        print(f\"--- Ridge Regression (alpha={alpha}) ---\")\n",
    "        print(f\"Predictors: {predictors}\")\n",
    "        print(f\"R-squared (Train): {r_squared:.4f}\")\n",
    "        print(f\"Number of non-zero coefficients: {sum(1 for c in model.coef_ if abs(c) > 1e-9)}\") # Always equal to len(predictors) in Ridge\n",
    "        print('\\n' + results_df.to_string(index=False, float_format='{:.6f}'.format))\n",
    "\n",
    "        print('\\n'+'-'*90+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "260946d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4381\n",
      "Number of non-zero coefficients: 2\n",
      "\n",
      "    Predictor  Coefficient\n",
      "    Intercept     0.758856\n",
      "  uncertainty     0.044219\n",
      "n_experiments     0.022845\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['degree_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4842\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "     Predictor  Coefficient\n",
      "     Intercept     0.758856\n",
      "degree_average     0.016060\n",
      "   uncertainty     0.044783\n",
      " n_experiments     0.023050\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4399\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "    Predictor  Coefficient\n",
      "    Intercept     0.758856\n",
      "  degree_gini    -0.003163\n",
      "  uncertainty     0.044205\n",
      "n_experiments     0.022887\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4381\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.758856\n",
      "clustering_average     0.000088\n",
      "       uncertainty     0.044219\n",
      "     n_experiments     0.022848\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['degree_average', 'degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4844\n",
      "Number of non-zero coefficients: 4\n",
      "\n",
      "     Predictor  Coefficient\n",
      "     Intercept     0.758856\n",
      "degree_average     0.015940\n",
      "   degree_gini    -0.000815\n",
      "   uncertainty     0.044776\n",
      " n_experiments     0.023059\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['degree_average', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4845\n",
      "Number of non-zero coefficients: 4\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.758856\n",
      "    degree_average     0.016138\n",
      "clustering_average     0.001162\n",
      "       uncertainty     0.044785\n",
      "     n_experiments     0.023083\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4399\n",
      "Number of non-zero coefficients: 4\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.758856\n",
      "       degree_gini    -0.003166\n",
      "clustering_average     0.000138\n",
      "       uncertainty     0.044205\n",
      "     n_experiments     0.022890\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['degree_average', 'degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4846\n",
      "Number of non-zero coefficients: 5\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.758856\n",
      "    degree_average     0.016017\n",
      "       degree_gini    -0.000822\n",
      "clustering_average     0.001166\n",
      "       uncertainty     0.044777\n",
      "     n_experiments     0.023092\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge_subsets(df_densify, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f258a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4976\n",
      "Number of non-zero coefficients: 2\n",
      "\n",
      "    Predictor  Coefficient\n",
      "    Intercept     0.762036\n",
      "  uncertainty     0.051188\n",
      "n_experiments     0.026173\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.5435\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "    Predictor  Coefficient\n",
      "    Intercept     0.762036\n",
      "  degree_gini    -0.017431\n",
      "  uncertainty     0.051180\n",
      "n_experiments     0.026511\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.5010\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.762036\n",
      "clustering_average    -0.004761\n",
      "       uncertainty     0.051200\n",
      "     n_experiments     0.026213\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Ridge Regression (alpha=1.0) ---\n",
      "Predictors: ['degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.5440\n",
      "Number of non-zero coefficients: 4\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.762036\n",
      "       degree_gini    -0.017115\n",
      "clustering_average    -0.001874\n",
      "       uncertainty     0.051185\n",
      "     n_experiments     0.026521\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge_subsets(df_equalize, main_predictors=['degree_gini', 'clustering_average'], alpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b2636",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d831c",
   "metadata": {},
   "source": [
    "This function uses L1 regularization via sklearn.linear_model.Lasso. LASSO is particularly useful for feature selection as it can drive the coefficients of less important predictors exactly to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d306b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_subsets(\n",
    "    df: pd.DataFrame, \n",
    "    fixed_predictors = ['uncertainty', 'n_experiments'], \n",
    "    main_predictors = ['degree_average', 'degree_gini', 'clustering_average'], \n",
    "    target = 'conclusion',\n",
    "    alpha=0.01 # A smaller alpha is often a better starting point for Lasso\n",
    "):\n",
    "    \"\"\"\n",
    "    Fits LASSO regression models for all subsets of main_predictors.\n",
    "    \"\"\"\n",
    "    # Generate all non-empty subsets\n",
    "    def all_subsets(lst):\n",
    "        # Includes the empty subset for completeness, which results in fixed_predictors only\n",
    "        return chain.from_iterable(combinations(lst, r) for r in range(0, len(lst)+1))\n",
    "\n",
    "    for subset in all_subsets(main_predictors):\n",
    "        predictors = list(subset) + fixed_predictors\n",
    "        X = df[predictors]\n",
    "        y = df[target]\n",
    "\n",
    "        # Normalize predictors\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=predictors, index=X.index)\n",
    "        \n",
    "        # Fit LASSO model\n",
    "        # NOTE: We use a small alpha (e.g., 0.01) to allow for some coefficients to remain non-zero.\n",
    "        model = Lasso(alpha=alpha, random_state=42, max_iter=10000) # Increased max_iter for robustness\n",
    "        model.fit(X_scaled_df, y)\n",
    "        \n",
    "        # Extract results\n",
    "        # Intercept is stored separately in sklearn\n",
    "        coef_names = ['Intercept'] + predictors\n",
    "        coefficients = [model.intercept_] + list(model.coef_)\n",
    "        r_squared = model.score(X_scaled_df, y) # R^2 on the training data\n",
    "        \n",
    "        # Build a tidy results table for this model\n",
    "        results_df = pd.DataFrame({\n",
    "            'Predictor': coef_names,\n",
    "            'Coefficient': coefficients,\n",
    "        })\n",
    "\n",
    "        # Print formatted output: predictor table and R-squared\n",
    "        print(f\"--- LASSO Regression (alpha={alpha}) ---\")\n",
    "        print(f\"Predictors: {predictors}\")\n",
    "        print(f\"R-squared (Train): {r_squared:.4f}\")\n",
    "        # Count non-zero coefficients. LASSO is known for setting coefficients exactly to zero.\n",
    "        print(f\"Number of non-zero coefficients: {sum(1 for c in model.coef_ if abs(c) > 1e-9)}\") \n",
    "        print('\\n' + results_df.to_string(index=False, float_format='{:.6f}'.format))\n",
    "\n",
    "        print('\\n'+'-'*90+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c641758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4018\n",
      "Number of non-zero coefficients: 2\n",
      "\n",
      "    Predictor  Coefficient\n",
      "    Intercept     0.758856\n",
      "  uncertainty     0.034080\n",
      "n_experiments     0.012702\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['degree_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4283\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "     Predictor  Coefficient\n",
      "     Intercept     0.758856\n",
      "degree_average     0.005571\n",
      "   uncertainty     0.034276\n",
      " n_experiments     0.012773\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4018\n",
      "Number of non-zero coefficients: 2\n",
      "\n",
      "    Predictor  Coefficient\n",
      "    Intercept     0.758856\n",
      "  degree_gini    -0.000000\n",
      "  uncertainty     0.034080\n",
      "n_experiments     0.012702\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4018\n",
      "Number of non-zero coefficients: 2\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.758856\n",
      "clustering_average    -0.000000\n",
      "       uncertainty     0.034080\n",
      "     n_experiments     0.012702\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['degree_average', 'degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4283\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "     Predictor  Coefficient\n",
      "     Intercept     0.758856\n",
      "degree_average     0.005571\n",
      "   degree_gini    -0.000000\n",
      "   uncertainty     0.034276\n",
      " n_experiments     0.012773\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['degree_average', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4283\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.758856\n",
      "    degree_average     0.005571\n",
      "clustering_average     0.000000\n",
      "       uncertainty     0.034276\n",
      "     n_experiments     0.012773\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4018\n",
      "Number of non-zero coefficients: 2\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.758856\n",
      "       degree_gini    -0.000000\n",
      "clustering_average    -0.000000\n",
      "       uncertainty     0.034080\n",
      "     n_experiments     0.012702\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['degree_average', 'degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4283\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.758856\n",
      "    degree_average     0.005571\n",
      "       degree_gini    -0.000000\n",
      "clustering_average     0.000000\n",
      "       uncertainty     0.034276\n",
      "     n_experiments     0.012773\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lasso_subsets(df_densify, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770315fd",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- LASSO consistently drives Gini and Clustering to zero, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "99a07357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4673\n",
      "Number of non-zero coefficients: 2\n",
      "\n",
      "    Predictor  Coefficient\n",
      "    Intercept     0.762036\n",
      "  uncertainty     0.041160\n",
      "n_experiments     0.016140\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4975\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "    Predictor  Coefficient\n",
      "    Intercept     0.762036\n",
      "  degree_gini    -0.007242\n",
      "  uncertainty     0.041156\n",
      "n_experiments     0.016280\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4673\n",
      "Number of non-zero coefficients: 2\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.762036\n",
      "clustering_average    -0.000000\n",
      "       uncertainty     0.041160\n",
      "     n_experiments     0.016140\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "--- LASSO Regression (alpha=0.01) ---\n",
      "Predictors: ['degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared (Train): 0.4975\n",
      "Number of non-zero coefficients: 3\n",
      "\n",
      "         Predictor  Coefficient\n",
      "         Intercept     0.762036\n",
      "       degree_gini    -0.007242\n",
      "clustering_average    -0.000000\n",
      "       uncertainty     0.041156\n",
      "     n_experiments     0.016280\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lasso_subsets(df_equalize, main_predictors=['degree_gini', 'clustering_average'], alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a480d",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- LASSO consistently drives Clustering to zero, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42e3ea",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80dd943",
   "metadata": {},
   "source": [
    "Note:\n",
    "Elastic Net introduces bias by shrinking coefficient estimates toward zero through regularization (controlled by ). This bias-variance trade-off reduces model variance and overfitting, often improving prediction accuracy. However, the magnitude of coefficients is underestimated, making them poor estimates of true effect sizes. While useful for feature selection and ranking, the coefficients should not be interpreted as unbiased measures of importance or causal impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0797248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_enet(\n",
    "        df: pd.DataFrame, \n",
    "        fixed_predictors: list[str]= ['uncertainty', 'n_experiments'], \n",
    "        main_predictors: list[str] = ['degree_average', 'degree_gini', 'clustering_average'], \n",
    "        target: str = 'conclusion',\n",
    "        n_bootstraps: int = 100,\n",
    "        l1_ratio: float | list[float]= [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],\n",
    "        selection_threshold: float = 1e-6\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Perform bootstrapped Elastic Net regression with variable selection over all subsets of main predictors.\n",
    "\n",
    "    Fits ElasticNetCV models on bootstrap samples for every combination of main_predictors \n",
    "    (e.g., 'degree_average', 'degree_gini', 'clustering_average') combined with fixed_predictors \n",
    "    (e.g., 'uncertainty', 'n_experiments'). For each predictor set:\n",
    "    \n",
    "    - Scales features using StandardScaler\n",
    "    - Uses 5-fold cross-validation to select optimal alpha and l1_ratio\n",
    "    - Aggregates coefficient means and selection frequencies across bootstraps\n",
    "    - Computes average R\n",
    "\n",
    "    Note: l1_ratio can be set to a float or a list of floats.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input data containing predictors and target variable.\n",
    "    fixed_predictors : list of str, default ['uncertainty', 'n_experiments']\n",
    "        Predictors included in all models.\n",
    "    main_predictors : list of str, default ['degree_average', 'degree_gini', 'clustering_average']\n",
    "        Predictors to evaluate in all possible subsets.\n",
    "    target : str, default 'conclusion'\n",
    "        Name of the target variable column in df.\n",
    "    n_bootstraps : int, default 100\n",
    "        Number of bootstrap iterations for stability assessment.\n",
    "    l1_ratio: float or list of float, default [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]\n",
    "        L1 ratio(s) used in cross-validation step.\n",
    "    selection_threshold : float, default 1e-6\n",
    "        Absolute coefficient threshold to count a variable as selected.\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    Prints for each predictor subset:\n",
    "        - List of predictors\n",
    "        - Average R across bootstraps\n",
    "        - Average R (adjusted) placeholder (currently not computed)\n",
    "        - Table of predictors, their average (normalized) coefficients, and selection frequency\n",
    "    \"\"\"   \n",
    "\n",
    "    def all_subsets(lst):\n",
    "        return chain.from_iterable(combinations(lst, r) for r in range(0, len(lst)+1))\n",
    "    \n",
    "    for subset in all_subsets(main_predictors):\n",
    "        predictors = list(subset) + fixed_predictors\n",
    "        X = df[predictors]\n",
    "        y = df[target]\n",
    "\n",
    "        # Store coefficient and selection count per predictor\n",
    "        coef_sum = {pred: 0.0 for pred in predictors}\n",
    "        selection_count = {pred: 0 for pred in predictors}\n",
    "        r2_sum = 0.0\n",
    "        r2_adj_sum = 0.0\n",
    "\n",
    "        for _ in tqdm(range(n_bootstraps)):\n",
    "            sample_idx = np.random.choice(X.index, size=len(X), replace=True)\n",
    "            X_boot, y_boot = X.loc[sample_idx], y.loc[sample_idx]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_boot)\n",
    "            \n",
    "            model = ElasticNetCV(\n",
    "                cv=5, \n",
    "                random_state=42, \n",
    "                l1_ratio=l1_ratio, \n",
    "                max_iter=1000,\n",
    "            )\n",
    "            \n",
    "            model.fit(X_scaled, y_boot)\n",
    "            \n",
    "            r2_sum += model.score(X_scaled, y_boot)\n",
    "            # r2_adj_sum = model.(X_scaled, y_boot)\n",
    "\n",
    "            for i, pred in enumerate(predictors):\n",
    "                if abs(model.coef_[i]) > selection_threshold:\n",
    "                    coef_sum[pred] += model.coef_[i]\n",
    "                    selection_count[pred] += 1\n",
    "                    \n",
    "\n",
    "        # Compute average coefficient and frequency\n",
    "        results = []\n",
    "        for pred in predictors:\n",
    "            avg_coef = coef_sum[pred] / n_bootstraps\n",
    "            freq = selection_count[pred] / n_bootstraps\n",
    "            results.append({'Predictor': pred, 'Coefficient': avg_coef, 'Frequency': freq})\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(f\"Predictors: {predictors}\")\n",
    "        print(f\"R-squared: {r2_sum/n_bootstraps:.4f}\\n\")\n",
    "        print(f\"R-squared (adjusted): {r2_adj_sum/n_bootstraps:.4f}\\n\")\n",
    "        print(results_df.to_string(index=False, float_format='{:.6f}'.format))\n",
    "        print('\\n' + '-'*90 + '\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "315975d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a8b9e63c414c77ae42a2e67a1d5a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['uncertainty', 'n_experiments']\n",
      "R-squared: 0.4391\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "    Predictor  Coefficient  Frequency\n",
      "  uncertainty     0.044329   1.000000\n",
      "n_experiments     0.022764   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c643689a76384b31ba22a6e2cb3e186f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['degree_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4831\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "     Predictor  Coefficient  Frequency\n",
      "degree_average     0.015864   1.000000\n",
      "   uncertainty     0.044808   1.000000\n",
      " n_experiments     0.022964   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb4c9297a1644ffb32353536dcf830b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4402\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "    Predictor  Coefficient  Frequency\n",
      "  degree_gini    -0.003120   1.000000\n",
      "  uncertainty     0.044153   1.000000\n",
      "n_experiments     0.022935   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaf937b5b48456a9e80c60d11ff89ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4382\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "         Predictor  Coefficient  Frequency\n",
      "clustering_average     0.000086   0.680000\n",
      "       uncertainty     0.043893   1.000000\n",
      "     n_experiments     0.022622   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4991b9f9d44d52be215ff34e16af1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['degree_average', 'degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4832\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "     Predictor  Coefficient  Frequency\n",
      "degree_average     0.015826   1.000000\n",
      "   degree_gini    -0.000772   0.840000\n",
      "   uncertainty     0.044551   1.000000\n",
      " n_experiments     0.022914   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0108c25e4f14457a3ae6916d20590a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['degree_average', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4835\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "         Predictor  Coefficient  Frequency\n",
      "    degree_average     0.015977   1.000000\n",
      "clustering_average     0.001102   0.860000\n",
      "       uncertainty     0.044698   1.000000\n",
      "     n_experiments     0.023042   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657ec66fe35748748019938fba0da9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4405\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "         Predictor  Coefficient  Frequency\n",
      "       degree_gini    -0.003013   1.000000\n",
      "clustering_average    -0.000052   0.780000\n",
      "       uncertainty     0.044101   1.000000\n",
      "     n_experiments     0.022835   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec8bffd50064899a5425c4ee7ed029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['degree_average', 'degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.4845\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "         Predictor  Coefficient  Frequency\n",
      "    degree_average     0.016005   1.000000\n",
      "       degree_gini    -0.000712   0.820000\n",
      "clustering_average     0.001072   0.900000\n",
      "       uncertainty     0.044507   1.000000\n",
      "     n_experiments     0.022927   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_enet(df_densify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b7c66199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4c23cce6be40bb88a92c873307e92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['uncertainty', 'n_experiments']\n",
      "R-squared: 0.4990\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "    Predictor  Coefficient  Frequency\n",
      "  uncertainty     0.051401   1.000000\n",
      "n_experiments     0.025963   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914aa005f80a435d98143f4aa7393fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['degree_gini', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.5437\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "    Predictor  Coefficient  Frequency\n",
      "  degree_gini    -0.017300   1.000000\n",
      "  uncertainty     0.051223   1.000000\n",
      "n_experiments     0.026466   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acd4e0902e243bb8492a3faf8d031f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.5005\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "         Predictor  Coefficient  Frequency\n",
      "clustering_average    -0.004715   1.000000\n",
      "       uncertainty     0.051041   1.000000\n",
      "     n_experiments     0.026131   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265aace5218f497d9b6dfc4d836ada09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['degree_gini', 'clustering_average', 'uncertainty', 'n_experiments']\n",
      "R-squared: 0.5450\n",
      "\n",
      "R-squared (adjusted): 0.0000\n",
      "\n",
      "         Predictor  Coefficient  Frequency\n",
      "       degree_gini    -0.017039   1.000000\n",
      "clustering_average    -0.001870   0.990000\n",
      "       uncertainty     0.051039   1.000000\n",
      "     n_experiments     0.026546   1.000000\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_enet(df_equalize, main_predictors=['degree_gini', 'clustering_average'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
