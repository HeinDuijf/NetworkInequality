{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- The resulting data can be found in the folder `data`. \n",
    "\n",
    "To do:\n",
    "\n",
    "- For some reason, I could not `dill.dump` the data. We should run the notebook once to ensure data in the folder `data` matches the outcome of the notebook.\n",
    "\n",
    "Clean up:\n",
    "\n",
    "1. `create_author_network`: Should we delete the lines of code that were commented out?\n",
    "2. Perceptron: The code for the perceptron is still in here; should we delete it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "from itertools import chain, chain#, batched\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pyalex import Works, Authors, Sources, Institutions, Concepts, Publishers, Funders, config\n",
    "\n",
    "config.email = \"h.w.a.duijf@uu.nl\"\n",
    "config.max_retries = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune citation data: only articles, and remove articles without bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_works_with_references(works: list) -> list:\n",
    "    works_pruned: list = []\n",
    "    for work in works:\n",
    "        try:\n",
    "            assert work[\"referenced_works\"] != []\n",
    "            works_pruned.append(work)\n",
    "        except:\n",
    "            pass\n",
    "    return works_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(works: list) -> list:\n",
    "    articles: list = []\n",
    "    for work in works:\n",
    "        try:\n",
    "            assert work[\"primary_location\"][\"source\"][\"type\"] == \"journal\"\n",
    "            assert work[\"type\"] == \"article\"\n",
    "            articles.append(work)\n",
    "        except:\n",
    "            pass\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create author network from dataframe of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_author_network(works: list, add_cited_authors: bool=True) -> nx.DiGraph:\n",
    "    \"\"\"Create a directed author citation network from a list of works.\n",
    "    Arguments\n",
    "    ---------\n",
    "    works : list[Work]\n",
    "        A list of works (see PyAlex).\n",
    "    add_cited_authors : bool, optional\n",
    "        Whether to add cited authors as nodes in the graph even if they are not present in the works list. Defaults to True.\n",
    "    Returns\n",
    "    -------\n",
    "    G : nx.DiGraph\n",
    "        A directed graph where nodes are authors and edges represent citations\n",
    "        from cited authors to citing authors.\"\"\"\n",
    "    # Create a directed graph and dataframe of works\n",
    "    df = pd.DataFrame(works)\n",
    "    G: nx.DiGraph = nx.DiGraph()\n",
    "\n",
    "    # Add nodes \n",
    "    for _, row in df.iterrows():\n",
    "        for author in row['authorships']:\n",
    "            this_author = author['author']['id'] \n",
    "            \n",
    "            # ignore the author with the id \"A9999999999\" as it is a placeholder for missing values\n",
    "            if (this_author is None) or (this_author.split(\"/\")[-1] == \"A9999999999\"): \n",
    "                continue\n",
    "            \n",
    "            # add the author if not already present in the network\n",
    "            if this_author not in G.nodes():\n",
    "                G.add_node(this_author)\n",
    "                G.nodes()[this_author]['n_works'] = 1\n",
    "            else:\n",
    "                G.nodes()[this_author]['n_works'] += 1\n",
    "            \n",
    "    # Add edges\n",
    "    for _, row in tqdm(df.iterrows(), total=len(works)):\n",
    "        for author in row['authorships']:\n",
    "            this_author = author['author']['id'] \n",
    "            if this_author not in G.nodes():\n",
    "                continue\n",
    "            \n",
    "            for cited_work_id in row[\"referenced_works\"]:\n",
    "                cited_work = df[df['id'] == cited_work_id] # This fails silently if citations are not present!\n",
    "                if len(cited_work) >= 1: # In case of multiple hits (shouldn't happen once sampling is fixed)\n",
    "                    cited_work = cited_work.iloc[0]\n",
    "                \n",
    "                for cited_author in cited_work['authorships']:\n",
    "                    cited_author = cited_author['author']['id'] \n",
    "                    \n",
    "                    if cited_author not in G.nodes() and add_cited_authors:\n",
    "                        if (cited_author is not None) and (cited_author.split(\"/\")[-1] != \"A9999999999\"): \n",
    "                            G.add_node(cited_author)\n",
    "                            G.nodes()[cited_author]['n_works'] = 0\n",
    "                    \n",
    "                    # edges go FROM cited TO citing\n",
    "                    if cited_author in G.nodes() and not G.has_edge(cited_author, this_author):\n",
    "                        G.add_edge(cited_author, this_author)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning by removing ‘twins’ (aka, strong co-authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_twins_dict(net: nx.DiGraph, records: list) -> dict:\n",
    "    \n",
    "    authors_twins_dict: dict = {}\n",
    "\n",
    "    for author_id in tqdm(net.nodes()):\n",
    "        author_records = [\n",
    "            work for work in records \n",
    "            if author_id in [author[\"author\"][\"id\"] for author in work[\"authorships\"]]]\n",
    "        \n",
    "        twins = set()\n",
    "        for k, record in enumerate(author_records):\n",
    "            if k == 0:\n",
    "                coauthors = [\n",
    "                    coauthor[\"author\"][\"id\"] \n",
    "                    for coauthor in record[\"authorships\"]\n",
    "                    if coauthor[\"author\"][\"id\"] != author_id\n",
    "                ]\n",
    "                twins = set(coauthors)\n",
    "            elif twins == set():\n",
    "                break\n",
    "            else:\n",
    "                coauthors = [\n",
    "                    coauthor[\"author\"][\"id\"] \n",
    "                    for coauthor in record[\"authorships\"]\n",
    "                    if coauthor[\"author\"][\"id\"] != author_id\n",
    "                ]\n",
    "                twins = twins.intersection(set(coauthors))\n",
    "        if twins:\n",
    "            authors_twins_dict[author_id] = twins\n",
    "    return authors_twins_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_network(net: nx.DiGraph, authors_twins_dict: dict) -> nx.DiGraph:\n",
    "    network_pruned = copy.deepcopy(net)\n",
    "    for author_id, twins in tqdm(authors_twins_dict.items()):\n",
    "        twins_in_network = [twin for twin in twins if twin in network_pruned.nodes()]\n",
    "        if twins_in_network:\n",
    "            network_pruned.remove_node(author_id)\n",
    "    return network_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning by taking the largest weakly connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_lcc(net: nx.DiGraph) -> nx.DiGraph:\n",
    "    # Extract largest component:\n",
    "    largest_cc = max(nx.weakly_connected_components(net), key=len)\n",
    "    \n",
    "    lcc = nx.DiGraph()\n",
    "    lcc.add_nodes_from((n, net.nodes[n]) for n in largest_cc)\n",
    "    lcc.add_edges_from((n, nbr, d)\n",
    "        for n, nbrs in net.adj.items() if n in largest_cc\n",
    "        for nbr, d in nbrs.items() if nbr in largest_cc)\n",
    "    lcc.graph.update(net.graph)\n",
    "    # lcc = copy.deepcopy(net.subgraph(largest_cc))\n",
    "    return lcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_self_loops(net: nx.DiGraph) -> nx.DiGraph:\n",
    "    network_pruned = copy.deepcopy(net).copy()\n",
    "    for node in net.nodes():\n",
    "        if (node, node) in net.edges():\n",
    "            network_pruned.remove_edge(node, node)\n",
    "    return network_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation data from OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_version(self, v):\n",
    "    self._add_params(\"data-version\", str(v))\n",
    "    return self\n",
    "\n",
    "Works.version = set_version\n",
    "\n",
    "# results = Works().filter(publication_year=2020).version(2).get()\n",
    "\n",
    "def OA_full_text_search(text: str, year: str, version: int=1) -> list:\n",
    "    \"\"\"Note: version=1 takes the old OA, version=2 takes the new OA Waldren\"\"\"\n",
    "    query = Works().search(f'\"{text}\"').filter(publication_year=year).version(version)\n",
    "    works: list = []\n",
    "\n",
    "    for _, work in enumerate(chain(*query.paginate(per_page=200, n_max=None))):\n",
    "        works.append(work)\n",
    "    print(f\"{len(works)=:,}\")\n",
    "    return works\n",
    "\n",
    "def OA_title_abstract_search(text: str, year: str, version: int=1) -> list:\n",
    "    \"\"\"Note: version=1 takes the old OA, version=2 takes the new OA Waldren\"\"\"\n",
    "    query = Works().search_filter(title_and_abstract=f'\"{text}\"').filter(publication_year=year).version(version)\n",
    "    works: list = []\n",
    "\n",
    "    for _, work in enumerate(chain(*query.paginate(per_page=200, n_max=None))):\n",
    "        works.append(work)\n",
    "    print(f\"{len(works)=:,}\")\n",
    "    return works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peptic ulcer disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(works)=383\n",
      "267\n"
     ]
    }
   ],
   "source": [
    "w1 = OA_title_abstract_search(text=\"peptic ulcer disease\", year=\"1900-1978\")\n",
    "w1_articles = get_articles(w1)\n",
    "print(len(w1_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(works)=490\n",
      "355\n"
     ]
    }
   ],
   "source": [
    "w2 = OA_title_abstract_search(text=\"peptic ulcer disease\", year=\"1900-1978\", version=2)\n",
    "w2_articles = get_articles(w2)\n",
    "print(len(w2_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(works)=685\n"
     ]
    }
   ],
   "source": [
    "string = \"peptic ulcer disease\"\n",
    "works_pud = OA_full_text_search(text=string, year=\"1900-1978\", version=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(works)=2,146\n"
     ]
    }
   ],
   "source": [
    "string = \"peptic ulcer disease\"\n",
    "works_pud = OA_full_text_search(text=string, year=\"1900-1978\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pud_works.pkl', 'wb') as f:\n",
    "    dill.dump(works_pud, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pud_works.pkl', 'rb') as f:\n",
    "    works_pud = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(works_pud_pruned)=1,464\n"
     ]
    }
   ],
   "source": [
    "works_pud_pruned = get_works_with_references(works_pud)\n",
    "print(f\"{len(works_pud_pruned)=:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(articles_pud)=1,276\n"
     ]
    }
   ],
   "source": [
    "articles_pud = get_articles(works_pud_pruned)\n",
    "print(f\"{len(articles_pud)=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create author-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447649aeeb56481d98a485ae4f485b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_pud_original.number_of_nodes()=2,601\n",
      "network_pud_original.number_of_edges()=3,257\n"
     ]
    }
   ],
   "source": [
    "network_pud_original = create_author_network(articles_pud) \n",
    "print(f\"{network_pud_original.number_of_nodes()=:,}\")\n",
    "print(f\"{network_pud_original.number_of_edges()=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prune author-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c249a7ebf6774349897e9f3bec00c7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fd69e286a14106bd3b8aa334a6f215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_pud_pruned.number_of_nodes()=1,035\n",
      "network_pud_pruned.number_of_edges()=739\n",
      "network_pud_pruned_lcc.number_of_nodes()=312\n",
      "network_pud_pruned_lcc.number_of_edges()=628\n",
      "network_pud_final.number_of_nodes()=312\n",
      "network_pud_final.number_of_edges()=583\n"
     ]
    }
   ],
   "source": [
    "authors_twins_dict = generate_twins_dict(network_pud_original, works_pud)\n",
    "network_pud_pruned = prune_network(network_pud_original, authors_twins_dict)\n",
    "print(f\"{network_pud_pruned.number_of_nodes()=:,}\")\n",
    "print(f\"{network_pud_pruned.number_of_edges()=:,}\")\n",
    "\n",
    "network_pud_pruned_lcc = produce_lcc(network_pud_pruned)\n",
    "print(f\"{network_pud_pruned_lcc.number_of_nodes()=:,}\")\n",
    "print(f\"{network_pud_pruned_lcc.number_of_edges()=:,}\")\n",
    "\n",
    "network_pud_final = remove_self_loops(network_pud_pruned_lcc)\n",
    "print(f\"{network_pud_final.number_of_nodes()=:,}\")\n",
    "print(f\"{network_pud_final.number_of_edges()=:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>number_of_nodes</th>\n",
       "      <th>number_of_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>works</td>\n",
       "      <td>2,146</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>works with refs</td>\n",
       "      <td>1,464</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>articles</td>\n",
       "      <td>1,276</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>author network</td>\n",
       "      <td>2,601</td>\n",
       "      <td>3,257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author network pruned</td>\n",
       "      <td>1,035</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>author network pruned lcc</td>\n",
       "      <td>312</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>author network final</td>\n",
       "      <td>312</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data_type number_of_nodes number_of_edges\n",
       "0                      works           2,146             N/A\n",
       "1            works with refs           1,464             N/A\n",
       "2                   articles           1,276             N/A\n",
       "3             author network           2,601           3,257\n",
       "4      author network pruned           1,035             739\n",
       "5  author network pruned lcc             312             628\n",
       "6       author network final             312             583"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_dict = {\n",
    "    \"data_type\": \n",
    "        [\"works\", \n",
    "        \"works with refs\", \n",
    "        \"articles\", \n",
    "        \"author network\",\n",
    "        \"author network pruned\",\n",
    "        \"author network pruned lcc\",\n",
    "        \"author network final\"],\n",
    "    \"number_of_nodes\": [\n",
    "        f\"{len(works_pud):,.0f}\", \n",
    "        f\"{len(works_pud_pruned):,.0f}\", \n",
    "        f\"{len(articles_pud):,.0f}\", \n",
    "        f\"{network_pud_original.number_of_nodes():,.0f}\", \n",
    "        f\"{network_pud_pruned.number_of_nodes():,.0f}\", \n",
    "        f\"{network_pud_pruned_lcc.number_of_nodes():,.0f}\", \n",
    "        f\"{network_pud_final.number_of_nodes():,.0f}\"\n",
    "    ],\n",
    "    \"number_of_edges\": [\n",
    "        \"N/A\",  # works do not have edges\n",
    "        \"N/A\",  # works with refs do not have edges\n",
    "        \"N/A\",  # articles do not have edges\n",
    "        f\"{network_pud_original.number_of_edges():,.0f}\", \n",
    "        f\"{network_pud_pruned.number_of_edges():,.0f}\", \n",
    "        f\"{network_pud_pruned_lcc.number_of_edges():,.0f}\", \n",
    "        f\"{network_pud_final.number_of_edges():,.0f}\"\n",
    "    ]\n",
    "}\n",
    "df_info = pd.DataFrame(info_dict)\n",
    "# df_info.astype({\"number_of_edges\": \"Int64\"})\n",
    "df_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/pud_works.pkl', 'w') as f:\n",
    "#     dill.dump(works_pud, f)\n",
    "\n",
    "# with open('data/pud_original.pkl', 'wb') as f:\n",
    "#     dill.dump(network_pud_original, f)\n",
    "\n",
    "with open('pud_final.pkl', 'wb') as f:\n",
    "    dill.dump(network_pud_final, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pud_final.pkl', 'rb') as f:\n",
    "    network = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(works)=13,636\n"
     ]
    }
   ],
   "source": [
    "string = \"perceptron\"\n",
    "works_perceptron = OA_full_text_search(text=string, year=\"1900-2000\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(works_perceptron_pruned)=9,840\n"
     ]
    }
   ],
   "source": [
    "works_perceptron_pruned = get_works_with_references(works_perceptron)\n",
    "print(f\"{len(works_perceptron_pruned)=:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(articles_perceptron)=7,668\n"
     ]
    }
   ],
   "source": [
    "articles_perceptron = get_articles(works_perceptron_pruned)\n",
    "print(f\"{len(articles_perceptron)=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create author-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f104f700be4d74848a54bc8168be43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_perceptron_original.number_of_nodes()=12,673\n",
      "network_perceptron_original.number_of_edges()=69,734\n"
     ]
    }
   ],
   "source": [
    "network_perceptron_original = create_author_network(articles_perceptron) \n",
    "print(f\"{network_perceptron_original.number_of_nodes()=:,}\")\n",
    "print(f\"{network_perceptron_original.number_of_edges()=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prune author-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a77a503b4e44dfbdfa981640e12fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa39c7bb7bd484690901e420db5f862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10321 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_perceptron_pruned.number_of_nodes()=4,306\n",
      "network_perceptron_pruned.number_of_edges()=19,932\n",
      "network_perceptron_pruned_lcc.number_of_nodes()=3,176\n",
      "network_perceptron_pruned_lcc.number_of_edges()=19,859\n",
      "network_perceptron_final.number_of_nodes()=3,176\n",
      "network_perceptron_final.number_of_edges()=18,914\n"
     ]
    }
   ],
   "source": [
    "authors_twins_dict = generate_twins_dict(network_perceptron_original, articles_perceptron)\n",
    "network_perceptron_pruned = prune_network(network_perceptron_original, authors_twins_dict)\n",
    "print(f\"{network_perceptron_pruned.number_of_nodes()=:,}\")\n",
    "print(f\"{network_perceptron_pruned.number_of_edges()=:,}\")\n",
    "\n",
    "network_perceptron_pruned_lcc = produce_lcc(network_perceptron_pruned)\n",
    "print(f\"{network_perceptron_pruned_lcc.number_of_nodes()=:,}\")\n",
    "print(f\"{network_perceptron_pruned_lcc.number_of_edges()=:,}\")\n",
    "\n",
    "network_perceptron_final = remove_self_loops(network_perceptron_pruned_lcc)\n",
    "print(f\"{network_perceptron_final.number_of_nodes()=:,}\")\n",
    "print(f\"{network_perceptron_final.number_of_edges()=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/perceptron_works.pkl', 'wb') as f:\n",
    "#     dill.dump(works_perceptron, f)\n",
    "\n",
    "# with open('data/perceptron_original.pkl', 'wb') as f:\n",
    "#     dill.dump(network_perceptron_original, f)\n",
    "    \n",
    "with open('perceptron_final_dill.pkl', 'wb') as f:\n",
    "    dill.dump(network_perceptron_final, f)\n",
    "\n",
    "# Save the object to a file\n",
    "with open('perceptron_final.pkl', 'wb') as f:\n",
    "    pickle.dump(network_perceptron_final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>number_of_nodes</th>\n",
       "      <th>number_of_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>works</td>\n",
       "      <td>13,636</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>works with refs</td>\n",
       "      <td>9,840</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>articles</td>\n",
       "      <td>7,668</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>author network</td>\n",
       "      <td>12,673</td>\n",
       "      <td>69,734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author network pruned</td>\n",
       "      <td>4,306</td>\n",
       "      <td>19,932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>author network pruned lcc</td>\n",
       "      <td>3,176</td>\n",
       "      <td>19,859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>author network final</td>\n",
       "      <td>3,176</td>\n",
       "      <td>18,914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data_type number_of_nodes number_of_edges\n",
       "0                      works          13,636             N/A\n",
       "1            works with refs           9,840             N/A\n",
       "2                   articles           7,668             N/A\n",
       "3             author network          12,673          69,734\n",
       "4      author network pruned           4,306          19,932\n",
       "5  author network pruned lcc           3,176          19,859\n",
       "6       author network final           3,176          18,914"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_dict = {\n",
    "    \"data_type\": \n",
    "        [\"works\", \n",
    "        \"works with refs\", \n",
    "        \"articles\", \n",
    "        \"author network\",\n",
    "        \"author network pruned\",\n",
    "        \"author network pruned lcc\",\n",
    "        \"author network final\"],\n",
    "    \"number_of_nodes\": [\n",
    "        f\"{len(works_perceptron):,.0f}\", \n",
    "        f\"{len(works_perceptron_pruned):,.0f}\", \n",
    "        f\"{len(articles_perceptron):,.0f}\", \n",
    "        f\"{network_perceptron_original.number_of_nodes():,.0f}\", \n",
    "        f\"{network_perceptron_pruned.number_of_nodes():,.0f}\", \n",
    "        f\"{network_perceptron_pruned_lcc.number_of_nodes():,.0f}\", \n",
    "        f\"{network_perceptron_final.number_of_nodes():,.0f}\"\n",
    "    ],\n",
    "    \"number_of_edges\": [\n",
    "        \"N/A\",  # works do not have edges\n",
    "        \"N/A\",  # works with refs do not have edges\n",
    "        \"N/A\",  # articles do not have edges\n",
    "        f\"{network_perceptron_original.number_of_edges():,.0f}\", \n",
    "        f\"{network_perceptron_pruned.number_of_edges():,.0f}\", \n",
    "        f\"{network_perceptron_pruned_lcc.number_of_edges():,.0f}\", \n",
    "        f\"{network_perceptron_final.number_of_edges():,.0f}\"\n",
    "    ]\n",
    "}\n",
    "df_info = pd.DataFrame(info_dict)\n",
    "# df_info.astype({\"number_of_edges\": \"Int64\"})\n",
    "df_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
