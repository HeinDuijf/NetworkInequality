{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- The resulting data can be found in the folder `data`. \n",
    "\n",
    "To do:\n",
    "\n",
    "- For some reason, I could not `dill.dump` the data. We should run the notebook once to ensure data in the folder `data` matches the outcome of the notebook.\n",
    "\n",
    "Clean up:\n",
    "\n",
    "1. `create_author_network`: Should we delete the lines of code that were commented out?\n",
    "2. Perceptron: The code for the perceptron is still in here; should we delete it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "from itertools import chain, chain#, batched\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pyalex import Works, Authors, Sources, Institutions, Concepts, Publishers, Funders, config\n",
    "\n",
    "config.email = \"h.w.a.duijf@uu.nl\"\n",
    "config.max_retries = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune citation data: only articles, and remove articles without bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_works_with_references(works: list) -> list:\n",
    "    works_pruned: list = []\n",
    "    for work in works:\n",
    "        try:\n",
    "            assert work[\"referenced_works\"] != []\n",
    "            works_pruned.append(work)\n",
    "        except:\n",
    "            pass\n",
    "    return works_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(works: list) -> list:\n",
    "    articles: list = []\n",
    "    for work in works:\n",
    "        try:\n",
    "            assert work[\"primary_location\"][\"source\"][\"type\"] == \"journal\"\n",
    "            assert work[\"type\"] == \"article\"\n",
    "            articles.append(work)\n",
    "        except:\n",
    "            pass\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create author network from dataframe of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_author_network(works: list) -> nx.DiGraph:\n",
    "    # Create a directed graph\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(works)\n",
    "    G: nx.DiGraph = nx.DiGraph()\n",
    "\n",
    "\n",
    "    # Add nodes and edges\n",
    "    for _, row in tqdm(df.iterrows(), total=len(works)):\n",
    "        for author in row['authorships']:\n",
    "            this_author = author['author']['id'] \n",
    "            \n",
    "            # ignore the author with the id \"A9999999999\" as it is a placeholder for missing values\n",
    "            if this_author.split(\"/\")[-1] == \"A9999999999\": \n",
    "                continue\n",
    "            \n",
    "            # add the author if not already present in the network\n",
    "            if this_author not in G.nodes():\n",
    "                G.add_node(this_author)\n",
    "                # G.nodes()[this_author]['authored_paper_count'] = 1\n",
    "                # G.nodes()[this_author]['cited_count'] = 0\n",
    "                # G.nodes()[this_author]['titles'] = [row['title']]\n",
    "            # else:\n",
    "                # G.nodes()[this_author]['authored_paper_count'] += 1\n",
    "                # G.nodes()[this_author]['titles'].append(row['title'])\n",
    "            \n",
    "            # add edges\n",
    "            for cited_work_id in row[\"referenced_works\"]:\n",
    "                cited_work = df[df['id'] == cited_work_id] # This fails silently if citations are not present!\n",
    "                if len(cited_work) >= 1: # In case of multiple hits (shouldn't happen once sampling is fixed)\n",
    "                    cited_work = cited_work.iloc[0]\n",
    "                    \n",
    "                for cited_author in cited_work['authorships']:\n",
    "                    cited_author = cited_author['author']['id'] \n",
    "                    \n",
    "                    if cited_author not in G.nodes():\n",
    "                        G.add_node(cited_author)\n",
    "                        # G.nodes()[cited_author]['cited_count'] = 1\n",
    "                        # G.nodes()[cited_author]['authored_paper_count'] = 0\n",
    "                        # G.nodes()[cited_author]['titles'] = [cited_work['title']]\n",
    "                    # else:\n",
    "                        # G.nodes()[cited_author]['cited_count'] += 1\n",
    "                        # G.nodes()[cited_author]['titles'].append(cited_work['title'])\n",
    "                    \n",
    "                    \n",
    "                    if G.has_edge(cited_author, this_author):  # edges go FROM cited TO citing\n",
    "                        pass\n",
    "                    else:\n",
    "                        G.add_edge(cited_author, this_author)\n",
    "                            \n",
    "    # # Optionally, you can print the nodes and edges to verify\n",
    "    # print(f\"{len(G.nodes())=:,}\")\n",
    "    # print(f\"{len(G.edges())=:,}\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning by removing ‘twins’ (aka, strong co-authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_twins_dict(net: nx.DiGraph, records: list) -> dict:\n",
    "    \n",
    "    authors_twins_dict: dict = {}\n",
    "\n",
    "    for author_id in tqdm(net.nodes()):\n",
    "        author_records = [\n",
    "            work for work in records \n",
    "            if author_id in [author[\"author\"][\"id\"] for author in work[\"authorships\"]]]\n",
    "            \n",
    "        for k, record in enumerate(author_records):\n",
    "            if k == 0:\n",
    "                coauthors = [\n",
    "                    coauthor[\"author\"][\"id\"] \n",
    "                    for coauthor in record[\"authorships\"]\n",
    "                    if coauthor[\"author\"][\"id\"] != author_id\n",
    "                ]\n",
    "                twins = set(coauthors)\n",
    "            elif twins == set():\n",
    "                break\n",
    "            else:\n",
    "                coauthors = [\n",
    "                    coauthor[\"author\"][\"id\"] \n",
    "                    for coauthor in record[\"authorships\"]\n",
    "                    if coauthor[\"author\"][\"id\"] != author_id\n",
    "                ]\n",
    "                twins = twins.intersection(set(coauthors))\n",
    "        if twins:\n",
    "            authors_twins_dict[author_id] = twins\n",
    "    return authors_twins_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_network(net: nx.DiGraph, authors_twins_dict: dict) -> nx.DiGraph:\n",
    "    network_pruned = copy.deepcopy(net)\n",
    "    for author_id, twins in tqdm(authors_twins_dict.items()):\n",
    "        twins_in_network = [twin for twin in twins if twin in network_pruned.nodes()]\n",
    "        if twins_in_network:\n",
    "            network_pruned.remove_node(author_id)\n",
    "    return network_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning by taking the largest weakly connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_lcc(net: nx.DiGraph) -> nx.DiGraph:\n",
    "    # Extract largest component:\n",
    "    largest_cc = max(nx.weakly_connected_components(net), key=len)\n",
    "    lcc = copy.deepcopy(net.subgraph(largest_cc))\n",
    "    return lcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_self_loops(net: nx.DiGraph) -> nx.DiGraph:\n",
    "    network_pruned = copy.deepcopy(net).copy()\n",
    "    for node in net.nodes():\n",
    "        if (node, node) in net.edges():\n",
    "            network_pruned.remove_edge(node, node)\n",
    "    return network_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation data from OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_works_from_OA(text: str, year: str) -> list:\n",
    "    query = Works().search(text).filter(publication_year=year)\n",
    "    works: list = []\n",
    "\n",
    "    for _, work in enumerate(chain(*query.paginate(per_page=200, n_max=None))):\n",
    "        works.append(work)\n",
    "    print(f\"{len(works)=:,}\")\n",
    "    return works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peptic ulcer disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "works_pud = get_works_from_OA(text=\"peptic ulcer disease\", year=\"1900-1978\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works_pud_pruned = get_works_with_references(works_pud)\n",
    "print(f\"{len(works_pud_pruned)=:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_pud = get_articles(works_pud_pruned)\n",
    "print(f\"{len(articles_pud)=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create author-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_pud_original = create_author_network(articles_pud) \n",
    "print(f\"{network_pud_original.number_of_nodes()=:,}\")\n",
    "print(f\"{network_pud_original.number_of_edges()=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prune author-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_twins_dict = generate_twins_dict(network_pud_original, works_pud)\n",
    "network_pud_pruned = prune_network(network_pud_original, authors_twins_dict)\n",
    "print(f\"{network_pud_pruned.number_of_nodes()=:,}\")\n",
    "print(f\"{network_pud_pruned.number_of_edges()=:,}\")\n",
    "\n",
    "network_pud_pruned_lcc = produce_lcc(network_pud_pruned)\n",
    "print(f\"{network_pud_pruned_lcc.number_of_nodes()=:,}\")\n",
    "print(f\"{network_pud_pruned_lcc.number_of_edges()=:,}\")\n",
    "\n",
    "network_pud_final = remove_self_loops(network_pud_pruned_lcc)\n",
    "print(f\"{network_pud_final.number_of_nodes()=:,}\")\n",
    "print(f\"{network_pud_final.number_of_edges()=:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {\n",
    "    \"data_type\": \n",
    "        [\"works\", \n",
    "        \"works with refs\", \n",
    "        \"articles\", \n",
    "        \"author network\",\n",
    "        \"author network pruned\",\n",
    "        \"author network pruned lcc\",\n",
    "        \"author network final\"],\n",
    "    \"number_of_nodes\": [\n",
    "        len(works_pud), \n",
    "        len(works_pud_pruned), \n",
    "        len(articles_pud), \n",
    "        network_pud_original.number_of_nodes(), \n",
    "        network_pud_pruned.number_of_nodes(), \n",
    "        network_pud_pruned_lcc.number_of_nodes(), \n",
    "        network_pud_final.number_of_nodes()\n",
    "    ],\n",
    "    \"number_of_edges\": [\n",
    "        np.nan,  # works do not have edges\n",
    "        np.nan,  # works with refs do not have edges\n",
    "        np.nan,  # articles do not have edges\n",
    "        network_pud_original.number_of_edges(), \n",
    "        network_pud_pruned.number_of_edges(), \n",
    "        network_pud_pruned_lcc.number_of_edges(), \n",
    "        network_pud_final.number_of_edges()\n",
    "    ]\n",
    "}\n",
    "df_info = pd.DataFrame(info_dict)\n",
    "df_info.astype({\"number_of_edges\": \"Int64\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/pud_works.pkl', 'w') as f:\n",
    "#     dill.dump(works_pud, f)\n",
    "\n",
    "# with open('data/pud_original.pkl', 'wb') as f:\n",
    "#     dill.dump(network_pud_original, f)\n",
    "\n",
    "with open('pud_final_dill.pkl', 'wb') as f:\n",
    "    # f.write(\"hello world\".encode('utf-8'))  \n",
    "    dill.dump(network_pud_final, f)\n",
    "\n",
    "# Save the object to a file\n",
    "with open('pud_final.pkl', 'wb') as f:\n",
    "    pickle.dump(network_pud_final, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works_perceptron = get_works_from_OA(text=\"perceptron\", year=\"1900-2000\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works_perceptron_pruned = get_works_with_references(works_perceptron)\n",
    "print(f\"{len(works_perceptron_pruned)=:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_perceptron = get_articles(works_perceptron_pruned)\n",
    "print(f\"{len(articles_perceptron)=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create author-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_perceptron_original = create_author_network(articles_perceptron) \n",
    "print(f\"{network_perceptron_original.number_of_nodes()=:,}\")\n",
    "print(f\"{network_perceptron_original.number_of_edges()=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prune author-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_twins_dict = generate_twins_dict(network_perceptron_original, articles_perceptron)\n",
    "network_perceptron_pruned = prune_network(network_perceptron_original, authors_twins_dict)\n",
    "print(f\"{network_perceptron_pruned.number_of_nodes()=:,}\")\n",
    "print(f\"{network_perceptron_pruned.number_of_edges()=:,}\")\n",
    "\n",
    "network_perceptron_pruned_lcc = produce_lcc(network_perceptron_pruned)\n",
    "print(f\"{network_perceptron_pruned_lcc.number_of_nodes()=:,}\")\n",
    "print(f\"{network_perceptron_pruned_lcc.number_of_edges()=:,}\")\n",
    "\n",
    "network_perceptron_final = remove_self_loops(network_perceptron_pruned_lcc)\n",
    "print(f\"{network_perceptron_final.number_of_nodes()=:,}\")\n",
    "print(f\"{network_perceptron_final.number_of_edges()=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/perceptron_works.pkl', 'wb') as f:\n",
    "#     dill.dump(works_perceptron, f)\n",
    "\n",
    "# with open('data/perceptron_original.pkl', 'wb') as f:\n",
    "#     dill.dump(network_perceptron_original, f)\n",
    "    \n",
    "with open('perceptron_final_dill.pkl', 'wb') as f:\n",
    "    dill.dump(network_perceptron_final, f)\n",
    "\n",
    "# Save the object to a file\n",
    "with open('perceptron_final.pkl', 'wb') as f:\n",
    "    pickle.dump(network_perceptron_final, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
